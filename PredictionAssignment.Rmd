---
title: "Practical Machine Learning - Prediction Assignment"
author: "Nick Cotter"
date: "10 April 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Goal

Use data from personal fitness devices (in particular accelerometers on the belt, forearm, arm, and dumbell) of 6 participants to predict how well they performed an exercise.

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har 
(see the section on the Weight Lifting Exercise Dataset).

## Data

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


## Setup & Libraries

Let's set a seed for reproducability purposes:
```{r setseed}
set.seed(54321)
```

We will be using the following libraries:
```{r libraries, message=F, warning=F}
require(knitr)
require(caret)
require(randomForest)
```

# Load Data

```{r loaddata, cache=TRUE}
# load training data
pml_training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
# load testing data - for quiz
pml_testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))
dim(pml_training)
dim(pml_testing)
```
So we have 159 possible feature columns. We will pre-process the data before training the model to reduce the number of features.

# Pre-processing

## Cleaning The Training Data

Let's remove columns which only contain missing values.
```{r removeemptycolumns}
# remove columns with only missing values
pml_training <- pml_training[,colSums(is.na(pml_training)) == 0]
pml_testing <- pml_testing[,colSums(is.na(pml_testing)) == 0]
dim(pml_training)
dim(pml_testing)
```

Some of the columns are metadata that should not be included - let's remove them.
```{r removeirrelvantcolumns}
cols_to_remove <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
pml_training <- pml_training[, -which(names(pml_training) %in% cols_to_remove)]
pml_testing <- pml_testing[, -which(names(pml_testing) %in% cols_to_remove)]
dim(pml_training)
dim(pml_testing)
```

This has brought the number of possible features down from 159 to 52

# Building The Prediction Model

The classe variable has 5 levels:

```{r classevariable}
levels(pml_training$classe)
```

Each of these describes how well the exercise was performed; A indicates that the exercise was performed correctly, the others that it was not.

While a majority of exercises was performed correctly the distribution is pretty even:

```{r plotclasse}
barplot(summary(pml_training$classe), main="Exercise Outcome Distribution", xlab="Outcome (classe)",
        ylab = "Frequency")
```


## Partition the training data into training & test

Let's split the pml_training data into 75% training, 25% test. 

```{r partitiondata}
partitionIndices <- createDataPartition(y = pml_training$classe, p=0.75, list=FALSE)
training_set <- pml_training[partitionIndices, ]
testing_set <- pml_training[-partitionIndices, ]
dim(training_set)
dim(testing_set)
```


## Model Selection

This is a multiclass problem with 52 possible features. Random forests might be a good choice here.

Let's train a random forest:

```{r predictionmodel}
# model
model <- randomForest(classe ~ ., data=training_set, method="class")
```

And try it out on the test data:

```{r testsetaccuracy}
# prediction
prediction <- predict(model, testing_set, type="class")
confusionMatrix(prediction, testing_set$classe)
```

The accuracy of this model is 0.995. The expected out-of-sample error is 0.005, that is, 0.5%.

## Predictions For Test Set

Let's print the predictions for each of the tests.

```{r quizpredictions}
pml_testing_prediction <- predict(model, pml_testing, type="class")
pml_testing_prediction
```

## TODO cross validation
